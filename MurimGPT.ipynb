{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuNeHdwrZ7ZMx8RwlAuCcf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonhero/nanoGPT/blob/master/MurimGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6ABpcuKMQWx",
        "outputId": "26b0fa7d-ece4-428e-889a-d3459d32c407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.26.0\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.6.2)\n",
            "Collecting blobfile>=2\n",
            "  Downloading blobfile-2.0.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.9/dist-packages (from blobfile>=2->tiktoken) (3.9.0)\n",
            "Collecting pycryptodomex~=3.8\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.9/dist-packages (from blobfile>=2->tiktoken) (1.26.14)\n",
            "Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.9/dist-packages (from blobfile>=2->tiktoken) (4.9.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2.10)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodomex, charset-normalizer, requests, blobfile, tiktoken\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "Successfully installed blobfile-2.0.1 charset-normalizer-3.1.0 pycryptodomex-3.17 requests-2.28.2 tiktoken-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "!fc-cache -fv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyLPSnVqtsn2",
        "outputId": "cef945db-ecad-46f4-d5ed-291ceff088b7"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20180306-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHy0BzvcMhz3",
        "outputId": "25940106-3fed-4ead-e7e8-8b9a825fe9bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family'] = 'NanumBarunGothic'"
      ],
      "metadata": {
        "id": "0hs3LeAowaa2"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import tiktoken\n",
        "import os\n",
        "\n",
        "# Hyper Parameters\n",
        "batch_size = 64 # how many independent sequences will we process in parallel?\n",
        "block_size = 128 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "start_epoch = 0\n",
        "eval_interval = 500\n",
        "save_interval = 2000\n",
        "# learning_rate = 3e-4\n",
        "learning_rate = 1e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 256\n",
        "n_heads = 16\n",
        "n_layer = 6\n",
        "dropout = 0.2\n",
        "PATH=\"/content/drive/MyDrive/tmp/checkpoints/\"\n",
        "load = True\n",
        "# --------------------\n",
        "os.makedirs(PATH, exist_ok=True)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/korean_murim_book.txt\", \"r\", encoding=\"cp949\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "enc = tiktoken.get_encoding(\"gpt2\")\n",
        "encode = lambda s: enc.encode(s)\n",
        "decode = lambda l: enc.decode(l)\n",
        "vocab_size = enc.n_vocab\n",
        "\n",
        "# text = text[:100000]\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "Fyenm37CNR4J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss(model):\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "            out[split] = loss.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x) # (B, T, C)\n",
        "        q = self.query(x) # (B, T, C)\n",
        "\n",
        "        # compute attention scores\n",
        "        wei = q @ k.transpose(-2, -1) * C ** -0.5 # (B, T, C) @ (B, C, T) => (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\")) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        # perform the weighted aggregatoin of the values\n",
        "        v = self.value(x) # (B, T, C)\n",
        "        out = wei @ v # (B, T, C)\n",
        "        return out\n",
        "    \n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    # Multiple heads of self-attention in parallel\n",
        "    def __init__(self, num_heads, head_size) -> None:\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4*n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*n_embd, n_embd),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"Transformer block: communication followd by computation\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_heads):\n",
        "        # n_embd: embedding dimension, n_heads: the number of the heads \n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_heads\n",
        "        self.sa = MultiHeadAttention(n_heads, head_size)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x+self.sa(self.ln1(x))\n",
        "        x = x+self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each toekn directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.positional_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.sa_heads = MultiHeadAttention(n_heads, n_embd//n_heads)\n",
        "        # feed forward layer is needed for think about the self attention score \n",
        "        # when we pass the self attention score straight forward to the last layer \n",
        "        # it's hard to think about the meaning of the score\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_heads=n_heads) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "    \n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B, T) tensor of integes\n",
        "        # C is the Channel which represents the embedding table output size\n",
        "        # when we pass the idx to the token embedding table \n",
        "        # we get a embedidng tensor by the idx and get by one by one\n",
        "        token_emb = self.token_embedding_table(idx) # (B, T, C)\n",
        "        pos_emb = self.positional_embedding_table(torch.arange(T, device=device)) # (T, C)\n",
        "        x = token_emb + pos_emb\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x) # (B, T, vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the prediction\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            decoded_idx = decode([idx_next.item()])\n",
        "            print(decoded_idx, end =\" \")\n",
        "            # append sample index to the running sequnce\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aGknz88HMmiB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTLanguageModel().to(device)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.9)\n",
        "\n",
        "\n",
        "def save_model(epoch, model, optimizer):\n",
        "    model_state_dict = {\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"epoch\": epoch\n",
        "    }   \n",
        "    torch.save(model_state_dict, PATH+f\"epoch-{epoch}.tar\")\n",
        "\n",
        "\n",
        "if load: \n",
        "    model_state_dict = torch.load(PATH + f\"epoch-{iter}.tar\")\n",
        "\n",
        "    model.load_state_dict(model_state_dict[\"model\"])\n",
        "    optimizer.load_state_dict(model_state_dict[\"optimizer\"])\n",
        "    start_epoch = model_state_dict[\"epoch\"]"
      ],
      "metadata": {
        "id": "Q_vA_oWysHcO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmwxik12ScbL",
        "outputId": "091cf2ae-b9e8-4a04-f8e6-f967664e6c60"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTLanguageModel(\n",
            "  (token_embedding_table): Embedding(50257, 256)\n",
            "  (positional_embedding_table): Embedding(128, 256)\n",
            "  (sa_heads): MultiHeadAttention(\n",
            "    (heads): ModuleList(\n",
            "      (0): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (1): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (2): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (3): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (4): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (5): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (6): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (7): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (8): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (9): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (10): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (11): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (12): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (13): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (14): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (15): Head(\n",
            "        (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (1): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (3): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (4): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (5): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (6): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (7): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (8): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (9): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (10): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (11): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (12): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (13): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (14): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (15): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (1): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (3): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (4): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (5): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (6): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (7): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (8): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (9): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (10): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (11): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (12): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (13): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (14): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (15): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (2): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (1): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (3): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (4): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (5): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (6): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (7): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (8): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (9): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (10): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (11): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (12): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (13): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (14): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (15): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (3): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (1): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (3): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (4): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (5): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (6): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (7): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (8): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (9): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (10): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (11): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (12): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (13): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (14): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (15): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (4): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (1): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (3): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (4): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (5): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (6): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (7): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (8): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (9): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (10): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (11): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (12): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (13): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (14): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (15): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (5): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (1): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (2): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (3): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (4): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (5): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (6): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (7): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (8): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (9): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (10): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (11): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (12): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (13): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (14): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "          (15): Head(\n",
            "            (key): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (query): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (value): Linear(in_features=256, out_features=16, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedForward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  (lm_head): Linear(in_features=256, out_features=50257, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(start_epoch, start_epoch+max_iters):\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0:\n",
        "        losses = estimate_loss(model=model)\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # scheduler.step()\n",
        "\n",
        "    if (iter+1) % save_interval == 0:\n",
        "        save_model(iter, model, optimizer)\n",
        "        print(f\"iter: {iter} | {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKqZVpGrNjsW",
        "outputId": "abc27fe2-0330-426b-a03c-4b70ab32bbe0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 10.9083, val loss 10.9085\n",
            "iter: 0 | 10.90560531616211\n",
            "step 500: train loss 2.3556, val loss 2.4205\n",
            "step 1000: train loss 1.9828, val loss 2.0243\n",
            "step 1500: train loss 1.8083, val loss 1.8191\n",
            "step 2000: train loss 1.7063, val loss 1.7127\n",
            "iter: 2000 | 1.7369993925094604\n",
            "step 2500: train loss 1.6231, val loss 1.6821\n",
            "step 3000: train loss 1.4932, val loss 1.5019\n",
            "step 3500: train loss 1.5179, val loss 1.5078\n",
            "step 4000: train loss 1.4207, val loss 1.4583\n",
            "iter: 4000 | 1.5182209014892578\n",
            "step 4500: train loss 1.3964, val loss 1.4679\n",
            "step 5000: train loss 1.4116, val loss 1.4269\n",
            "step 5500: train loss 1.3895, val loss 1.4527\n",
            "step 6000: train loss 1.3560, val loss 1.3965\n",
            "iter: 6000 | 1.4768617153167725\n",
            "step 6500: train loss 1.3719, val loss 1.4301\n",
            "step 7000: train loss 1.3501, val loss 1.4160\n",
            "step 7500: train loss 1.3771, val loss 1.3791\n",
            "step 8000: train loss 1.3758, val loss 1.4243\n",
            "iter: 8000 | 1.4491640329360962\n",
            "step 8500: train loss 1.3892, val loss 1.3524\n",
            "step 9000: train loss 1.3356, val loss 1.3611\n",
            "step 9500: train loss 1.3135, val loss 1.3339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-*-coding:utf-8\n",
        "# generate from the model\n",
        "import sys\n",
        "\n",
        "import io\n",
        "\n",
        "source = \"승현은 세마고에서 전투를 벌이고 있었다.\"\n",
        "\n",
        "# context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "context = torch.tensor(encode(source)).to(device)\n",
        "context = context.unsqueeze(0)\n",
        "# print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
        "result = decode(model.generate(context, max_new_tokens=5000)[0].tolist())\n",
        "\n",
        "with open('result.txt', \"w\", encoding=\"utf-8\") as f:\n",
        "    f.writelines(result)\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "5fGc0LY4NmEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1511ce1c-00aa-4e96-82f9-9d9584a8d1e6"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \n",
            " � � � � �  � � � � � � � �  � � � � � � � � � � � � � � � � �  � � � � � � � �  � � � � �  � � �   � � � � � � � � � � � .  � � � � � � � � �  � � � � � � � �  � � � � � � � � � � � �  � � � � � � � � � � � � � � �  � � � � � � � � � �  � � � � � � � � � � � � � � � � � � � � � � ,   � � � � � �   � � � � � � � � �  � � � � � � � � � � � � � . � � \n",
            " \n",
            " � � � � � � � � ,   � � � � � � � �  � � �  � � � � � �  � � � � � � � �   � � � � � � � �   � � � � � �   � � � � � � .  � � �  � � � � � �   � � � � � � � � �  � � � � � � � � � � � � � � � � � � � � �   � � � � � � � � �  hoped �  � � � � �   � � � � � �  � � � � � � � � . \n",
            " \n",
            " � � � � � � � � �  � � � � � � � � �   � � � � � � � � � � � . \n",
            " � � � � � � � � � � �   � � � � � � � �   � � � � � � � � � � � �  � � � � � � � � � � �  � � � � � � � � �  � � � � � � � � � � � �   � � � � � �  � � � � � � � � � � � � � � �   � � � � � �  � � �  � � � � � � � � � � � �   � � �  � � �  � � � � �   � � � � � � � �   � � � � � � � � . \n",
            " \n",
            " � � � � � � � � � � � � � � � � ( 天 � � 神 武 � � � ) � �  � � � � � �  � � � � � � � � � � � . � � \n",
            " \n",
            " � � � � � � � �  � � � � � � � � �  � � � � � � � � � � � �  � � � � � � � �  � � � � � � � � �   � � � � � � � � �  � � � � � � � �   � � � � � � � � � � .  � � � � � .   � � � � � � �  � � � � � � � � � � � �   � � � � � � � �  � � � � � � � � � � . � � \n",
            " \n",
            " � � � � � � � � � � � � � �  � � � � � � � � � � � � ? � � \n",
            " \n",
            " � � � � � � � � � � � �   � � �   � � � � � � � � � .   � � � � � � � � � � � � � � .  � � � � � � � �  � � �  � � �  � � � � � � � �  � � �  � � � � � � � .  � � � � � � � � � � �  � � � � � � � � � � � � � � �  � � �  � � � � � �  � � � � � � � �  � � �   � � � ,     � � � � �  � � �  � ��   � � � � � � � �   � � � � � �  � � �   � � � � � � � � � � �� � � �  � � �  � � � � � � � � � � . � � \n",
            " \n",
            " \n",
            " \" � � � O ? \n",
            " � � � � � ……  � � � ,  � � � ! � � � � � � ! \n",
            " � � � � � � � � � � � �  � � � � � �  � � � � � � � �  � � � � � � � � . \n",
            " \n",
            " � � � � � � � � � � � � � �  � � � � � � � �  � � � � � � � � � � �   � � � � � � � � � � �  � � � � � �  � � � � � �  � � �   � � � � �  � � � � � � � �  � � � � � � � � � � � �   � � � � � �   � � � � � . � � \n",
            " \n",
            " � �  � � � � � � � �  � � � � � �  � � � �� � � � � � � � �  � � � � � � . \n",
            " � � �  � � � � � �   � � �  � � �  � � � � � � � � � � � �  � � � � � � . � � \n",
            " \n",
            " � � � � � � � � � � � � � �   � � � � � � � � � � � � � �  � � � � � � � � � � � .  � � � � � �  � � � � � � � � � � � �   � � � � � � � � � � �  � � � � � � � � �  � � � � � � � � �  � � � � � � � � �  � � � � � �  � � � � � �  � � � � � � � �  � � � � � �   � � � � � �  � � � � � � � � �  � � � � � � � � � � � . \n",
            " � � � � � � � � �  � � � � � � � � � � � �  � � � � � �  � � � � � � � �  � � � � � � � �   � � � � � �  � � �  � � � � �  � � � � � �  � � � � � � � �   � � � � � �   � � � � � ,   � � � � �  � � � � � � � � � � � � � � � � �  � � � � � � � �  � � � � � �  � � � � � � � � �  � � � � � � � � � � � . \n",
            " � � � � � �   � � � � �� \n",
            " � � � � � � � � � � � �  � � � � �  � � � � � �   � � � � � � � �  � � � � � � � � � � �  � � �  � � � � � � � � �  � � � � � � � �   � � � � � �  � � � � � � � � � . \n",
            " � � � � � � � � ,  � � � � � �  � � � � � � � � �   � � � � � �  � � � � �� � � � � � �   � � � � � �   � � � � � . \n",
            " \n",
            " � ��  � � � � � � � � �  � � � � � � � � � � � �   � � � � �   � � � � � � � � �   � � � � � � � � � � � �   � � � � � � � � � � � � � � � � � � �   � � � � � � � �  � � � � �  � � � � � � � �  � � � � � � � � � � � �  � � � � � �  � � � � � � � � �  � � � � � � � � � �  � � � � � � � � �   � �  � � �  � � � � � �  � � � � � � � � � � � � �   � � �   � � � � � �  � � � � � �   � � � � � � � � �   � � � � � �  [ � � ,   � � � � � � ] � �   � � � � �  � � � � � � � � � � �  � � � � � � � � � ' � �   � � � � � � � �   � � � � � � � � �  � � � � � � �  � � �  � � � � � � � � � . \n",
            " \n",
            " � � � � �  � � � � � � � � � � . \n",
            " \n",
            " � � � � � � � � � � � �   � � � � � � � � � � � �  � � � � � � � � � � �  � � � � � � � � . \n",
            " � � � � � � � � �  � � � � � � � � �  � � � � � �   � � � � � � � �  � � � � � � � �  � � � � � � � � � � . \n",
            " � � � � � � � � � � � � �  � � � � � � � � �  � � � � � � � � �  � � � � � � � �   � � � � �   � � � � � . \n",
            " � � � � � �  � � � � � �  � � � � � �  � � � � � � � � � � � ? \n",
            " � � � � � � � � � � � � � � �   � � � � � �  � � �  � � � � � � � � � � �  � � � � � � � � �  � � � � � � ,  � � � � � �  � � � � � �  � � � � � � � � �  � � � � �   � � �  � � � � � � .  � � �   � � � � � � �  � � �  � � � � � � � � � � �  � � � � � � � � �  � � �  � � �  � � � � � � � � � � � � � �  � � �  � � � � � � �  � � �  � � � � � �  � � � � � �  � � � � � � � �  � � �  � � �  � � � � � � � �  � � �   � � � � � �   � � � � �  � � � � � � � � ? � �  � � � � � � � � � � �  � � � � � � � � �  � � � � � � �  � � � � � � � � �  � � � � � � � � �  � � � � � � � �  � � � � � � � � � � � . \n",
            " � � � � � � � �  � � � � � �  � � � � � � � � � � � � � ,  � � � � � � � �  � � � � � � � � �  � � � � � � � � �  � � � � � � .  � � �  � � � � �  � � �   � � �  � � � � � � . \n",
            " \n",
            " � � � � � � !  � � � � � � � � � ? � � \n",
            " \n",
            " � � �  � � � � �   � � � � � �  � � � � � � � � � � � �   � � � � � � � �  � � �  � � � � � �   � � 天 � � � � �  � � � � � � � �   � � � � � �  � � � � � �  � � �   � � � � � � � � �  � � � � � �  � � � � � �  � �� � � �  � � �   � �  � � � � � �  � � � � � � � � � � � � � � � � � . \n",
            "  7 � � �   � � � � � � � � �  � � � � � �  � � � � � � � � � � � � � � �  � � � � � � � � �   � � � � � � � � . \n",
            " \n",
            " ' � � � � � � � � � � � .' \n",
            " \n",
            " � � � � �  � � � � �   � � � � �   � � � � � � � � � � � . \n",
            " � � � � � �  � � � � � � � � �  � � � � � �  � � � � � � � �  � � � � � � � � � � � �  � � � � � � � � � � � � �  � � � � � �  � � � � � � � �  � � � � � �   � � � � � . \n",
            " \n",
            " 「 � � � � � ,   � � �  � � � � � �  � � � � � � � � �  � � � � � �   � � � � � � � � � � � .' \n",
            " \n",
            " � � � � � � � � ! \n",
            " \n",
            " � � � � � �  � � � � � �  � � � � � � � � � � � � ,  � � � � � � � � �  � � � � � � � � �  � � � � � � � �  � � � � � � � � � . \n",
            " \n",
            " � � � � � � � � � .  � � �   � � � � � � � � !  � � � � � � � � � ? � � \n",
            " \n",
            " � �� � � � � � �  � � � � � � � � � � � � � � �  � � � � � � � � � � � �  � � � � � � � �   � � � � � � . � �  \" � � � � � � � � � � � � � � �  � � � � � � � � � � �  � � � � � . � � \n",
            " \n",
            " 」 ...... !\" \n",
            " \n",
            " � � � � �  � � � � � � � � � � � .  � � � �   � � � � � �  � � � � � � � �   � � � � � �  � � � � �   � � �   � � � � � .  � � � � � �  � � � � � � � �   � � � � � � � � � � � . \n",
            " � � � � � � � � � � �  � � � � � �  � � � � � � � � �   � � � � �  � � � � �  � � � � � � � � � � � � � �  � � � � � � �  � � � � � � � � �  � � � � � � � � � � � . \n",
            " \n",
            " � � � � � � �   � � � � � � � � � � �  � � � � � �  � � �   � � � � � �  � � � � � � �  � � � � � � � � �   � � � � � �  � � � � � � ,  � � � � � � � � � � �  � � � � �� � � � � . \n",
            " � � � � � � � � � � � � � . \n",
            " � � � � � �  � � � � �  � � � � � �  � � � � � � � � � .  � � � � � � � � � � � .  � �� � � �   � � �   � � � � .  � � � � � � �  � � � � � �  � � � � �  � � � � �  � � �  � � � � � �   � � � � �  � � � � � � � � � � � �    � � � � � � � � � � . \n",
            " � � � � � � � � �  � � � � � �  � � � � � �  � � � � �  � � � � � � � �   � � � � � � � � . \n",
            " \n",
            " \" � � � � � � � � � � � � � � �  � � � � � � ( 天 � � � � � ),  � � � � � ,  � � � � � �  � � � � � �   � � � � � �  � � � � � � � � � � �  � � � � � � � � � � � � � � …… � � � � � �  � � � � � �  � � �  � � � . \n",
            " \n",
            " � � � � � � � � � � � � � � � � � �  � � � � � � ) � � �   � � � � �   � � � � � �  � � � � � � � � � �  � � � � � �  � � � � � �   � � � � � � . \n",
            " -  … � � � � � � �  � � � � � � � � �  � � �  � � � � � � � � � � � ? \n",
            " \n",
            " � � � � �  � � � � � �  � � �   � �  � � � � � � � � �  � � �  � � � � � �  � � � � � � � � �  � � � � � � � � . \n",
            " \n",
            " � � � � �  � � � � � ,   � � � � � � � � � � � � � � � !  � � � � � � � � � � �  � � � � � �  � � � . � � \n",
            " \n",
            " � � � � � � \n",
            " � �� � � � ,  � � � � � �  � � � � � �   � � � � � �  � � � � � �  � � � � � � � � � � � . \n",
            " \n",
            " � � � � � �   � � � � � � � �  � � � � � � � � �   � � � � � � � �  � � � � � � �  � � � � � � ,   � � � � �   � � � � � � �  � � � � � � �  � � � � � � � �  � �� � � � � � � � � � � . \n",
            " \n",
            " � � � � � � � � � �   � � � � �   � � � � � � ��  � � � � � � � � � � � �  � � � � � � � �  � � � � � �  � � � � � �  � � � � � �  � � � � � �  � � � � � � �  � � � � � .  � � � � � �  � � � � � � � � �  � � � ,  � � � � � � � � � � �  � � � � �   � � � � �  � � � � � � � � � ?  � � �  � � � � �   � � � � � � � � � � � . \n",
            " � � �   � � ? � � \n",
            " \n",
            " � � …… � � � � � �   � � � � �  � � � � � � � � � � .' \n",
            " \n",
            " � � �  � � � � � � � �  � � � � � � � � �  � � � � � � � �  � � � � � �   � � �  � � � � � � . � .  I \n",
            " \n",
            " � � � � � � � � � � � � � �  � � � � � �  � � � � � � � � �  � � � � � � � � � � � �  � � � � �  � � � � � �   � � �  � � � � � � � �  � � � � � � � � � � � � �  � � � � � � � � � � � �  � � � � � � � � � � �   � � �  � � � � � � � � � � � . \n",
            " \n",
            " � � � � � � � � � � � �  � � � � � � � � � � � . \n",
            " \n",
            " ' � � � � � � � � ……  � � � � � � � � � � � � � � � ,   � � � � � �  � � � � � � � �   � � � � � � � � � � � � � � � .  � �  ' � � � � � � � � � ,  � � �  � � � � �   � � � � � � � � �  � � � � � �  � � � � � � �  � � � � �� � � �  � � � � �  � � � � � � � � � � � �  � � � � �   � � � � � � � �  � � � � � � � � �  � � �  � � � � �  � � � � � �   � � � � � � � � �   � � � � � � � � � � � � �   � � � � � �   � �   � �  � � �  � � � � � �  � � � � � �   � � �  � � � � � � � . � � \n",
            " \n",
            " � � � � �  � � � � � � � � �   � � � � � � ( � � � � � � 一 � � � 5 ) � �  � � � � � � � � �  � � � � � � � � �  � � � � � � � � . \n",
            " � � � � �� � �  � � � � � �  � � � � � �  � � � . \n",
            " � � � � � � � � �  � � �  � � � � � � . \n",
            " � � � � � � � � �  � � � � � � � �  � � !. \n",
            " \n",
            " ' � � � � �  � � � � � � � � �   � � � � � � � � � � �  � �� � � � � � �  � � � � �  � � �  � � � � � � � � � � � �  � � � � � � � � � � � �   � � � � � � � � � � � � .' \n",
            " \n",
            " � � � � � �  � � � � � �  � � �  � � � � � �  � � � � � � � � � � .  � � � � � � � �  � � � � � � � �  � � � � � � � � �  � � � � � � � � �  � � � � � �  � � � � � � � � ,  � � �  � � � � � � � � � � � � � � � ( � � � � � � : \n",
            " \n",
            " � � � � � � .  � � � � � � . \n",
            " \n",
            " o   � � � � � � � � � � � � � �  � � � � � �  � � � � � �  � � � � � � � � � � � �  � � � � � �   � � � � � �   � � �  � � � � �  � � �  � � � � � � � � � � � � � . ' \n",
            " \n",
            "   � � � � � � � � �  � � � � � �  � � � � � �  � � �  � � � � � �  � ��  � � � � � � � � �   � � � � "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "LCwpSwEMRinp",
        "outputId": "27b2fdbc-0433-4e92-952c-789e839f7751"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'승현은 세마고에서 전투를 벌이고 있었다.\\n\\n말을 안괴한 동이에서는데 노름은 아니 코 했으니까. 달리도 지금의 얘기는지 모르겠지만 제쳐하니 밁으로였지지�만, 그런 겨외도 느낌이었다.”\\n\\n“무슨, 힘하고 마 맞는 생각인 하지만 틀나 가지. 젚 리가 타든는 서천마군요까지 항산검� hoped� 놈을 개로 어팔다.\\n\\n그리고 다그지 가돌갔다.\\n이제지기 한쐐도 그리그런 이렇건한 미추는 정은정음을 했권 쓰러트까지 거대 좀 남축기는 화 로 쥐의 궁격을 핌렸다.\\n\\n“천재적인그(天�神武辆)을 집상 믴놓았다.”\\n\\n“스무 종르를 짓옥밄�을 놈들이 노려를 호으로 유덕을 구했으�. 쫼다. �그럼 무미라는 귓가의 따라이다.”\\n\\n“백반왕던 일가라고?”\\n\\n노인터님은 그 하겠뜢�. 그렇거린다. 대상인 열 부 집어당 수 앞�고. 지내십을 쓰러트려던 채 끝에 다하는 쵀 고,  같은 싹 사 골골을 깨끘 서 확양시킬는 좀 부탁한다.”\\n\\n\\n\"어O?\\n검을…… 음, 응!’�똑!\\n아무리고 조각 시하를 찔렸다.\\n\\n“그렇으며 성신이 있었다고 하늘께서 자래 있어 선 하기 전반의 청노에서 결뿐 화다.”\\n\\n이 정도의 순간 “물걩이는 정보.\\n그 분념 괴 속 무공처럼 이런.”\\n\\n뒷언제름인 그때였다고 생각했다. 정찰 이상으로 가대장다 망찌고 있어서 비례는 얼마 보던 칠묵이 아직 교귄 몬�독을 일양였다.\\n근처럼 이렇기를 뭐면 말릆이 발밀한 타는 놈 일이 보기 때문인 결와 해도, 경이 아름니까까지 상호의 상산 중어볼 수역졌다.\\n그와 기사\\n용남으로 다해 처러 혼장을 누도하는 방 낙겘럽 당하게 휩쓸 여인이다.\\n팬경은, 어쩌 만까�한 힘게 의사겘럼 툴러 갔다.\\n\\n물 러브가 뚫려보던 검은 ��름음은 귀용으로 거리룻이면다고 해가도 다음 여라한 목소리가 로비 철구를 내리고� 이렇게 할 수 있는 나뿐이다는 건 그걸 모를 화는지 그는 [인, 경험]을 하면 유력직인 지부장\\'의 공력을 기욅훅 어륶� 도 드는데.\\n\\n아니 스연하다.\\n\\n제자으로 호호처럼 말일지도 않았다.\\n천문과 열리둘 명과 표하여 석룼의 존재이다.\\n이동한점에 익혔가 다르고 아름다 해야 하나.\\n나도 무슨 여고 있어하나?\\n쑤얼거리로 호청 일 년인데서 정�교을 멄지, 우리 봤어 어으를 잪은 게 아주. 맞 한확이 더 진태경을 도꾸도 없 을 아꺽정하는 색 칙�극 무 어떤 느지 창재한 지 서 성업이 된 글씀 같은 아닌가?” “어떻게 앞에는 죽음은 안에서 마줘진 애옹을 떠들었다.\\n하나만 데어 분위기보�, 출박한 좌패가 남기지 않지. 씩 신의 생 그 속도.\\n\\n“산�! 어찌어?”\\n\\n이� 묵을 가는 눈동자에 가늩을 바 서서 耜天먑이 천해상 교도 있는 신 구후에 다친 데에 사슨 작 한 법에 들어갔지랐다.\\n 7로 후그가 막상 먼저지르면 어떻게 가졌다.\\n\\n\\'제대시다.\\'\\n\\n팽이 닮은 팔이 그러졌다.\\n내가 스루쳐 있던 수련의 링입으로 출천한다고 내는 반복을 응시 했다.\\n\\n「일양, 그 정도 마명어 나는 공격이나.\\'\\n\\n“시�응!\\n\\n뭐라 워나 주시잖는, 오래른 무리가 일격을 약도야.\\n\\n“아니다. 녹 할까요! 얘셨요?”\\n\\n사제자 목유로부터 왜그러려 진경이 헤어.” \"마표거리는 �선체과 뗴다.”\\n\\n」......!\"\\n\\n이건 스폐트다. 족� 크기 신형이 고쳐 있을 것 간다. 내가 비장이 특격했다.\\n반양간을 찜려 따는지 한조 서의 연이자만욏 빈�려 전실에 전부였다.\\n\\n낲�와 평상이라 부위 받 퍼려 보듯� 들어온 갈감 나도, 누군가의 염물이다.\\n슕�살에야.\\n서신 바닥 득지 않으락. 돌아갔다. 뭔가 회 하다. 어디� 얼는 말이 아니 듯 잠에 호을 때려지는  녰억이다.\\n그리고 오늘 다섯 중의 때녉을 곁였다.\\n\\n\"�화신이라는 미쾌(天鷯卛), 아니, 아마 진위 혼에 대팬하게 내려다보자……，？ “은은 안 멋.\\n\\n보아성거리는 다지)분 과다 결고 싶얄�에 빠져 오는 것도.\\n- …산음을 마주가 늘 신입니까?\\n\\n검을 느낀 듯 해 멀리서 말 일을 입거려 던졌다.\\n\\n“외 아니, 혼란나리만! 우혁진을 입었 다.”\\n\\n，，\\n뭔데, 정실 듣는 크린 알고 떠올랐다.\\n\\n나는 공력이 침아온 화룡의 미속� 뺘진, 결을 향길� 노인은 아니라 사실이었다.\\n\\n근골에� 굳은 괴�물 속제에는 비장한 내밀 의전 이십 저미 쉽음이 없다. 오른 실신에 속, 주화란을 눈을 하자 누구요? 채 앞은 태임였다.\\n어 하?”\\n\\n“……지금 하여 말입니다.\\'\\n\\n싱 인간이 바람에 저하고 있던 그 순간.�. I\\n\\n마법다후과 방보 전성과 아주부터 듣은 손아 가 졌다면 아래들이인 늙헤도를 제작하는 그 순간했다.\\n\\n동실교가 발고했다.\\n\\n\\'아니면…… 열화야까지, 그때 종남의 테공위까지. � \\'그리고, 더 더한 근대로 남게 단단한 직킬가 노일 넘어떨진 말한 가슴을 념나기 시 전은 지나 가면과 호활하다는 것만 한 한 소 리로 오는 게 납니다.”\\n\\n이건 절만히 폭보(萖�死一鏣5)을 베구리 모러지 않았다.\\n쉽사해 올러 노도 어.\\n맹주기 때 리야.\\n그런데 대추일 �!.\\n\\n\\'조한 위죄를 긁적이고 뭔가가 이다 반 블람주를 바었다�는 고수처와.\\'\\n\\n아문 잡아 다 니던 목중이다. 전쟁은 심속이 다르는 무투를 석고 있었다, 난 베리러집심(蘭穱:\\n\\n띠링. 띠링.\\n\\no 후우지진의 코과 부르 끌어드는 지금 행령 그 상을 을 만태입니다.\\'\\n\\n 그리고 내짝 누신 듯 추는 사 어찌가 관�'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}